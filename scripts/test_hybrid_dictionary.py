"""í•˜ì´ë¸Œë¦¬ë“œ ì‚¬ì „ ì¡°íšŒ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸.

ì‹¤ì œ vocabulary ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ LLM+API í•˜ì´ë¸Œë¦¬ë“œ ì¡°íšŒ ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
pytestì—ì„œ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ (ìˆ˜ë™ ì‹¤í–‰ ì „ìš©).

Usage:
    PYTHONPATH=src uv run python scripts/test_hybrid_dictionary.py [--count 10]
"""

import asyncio
import argparse
import random
import time
import json
from dotenv import load_dotenv

load_dotenv()

from adapter.mongodb.connection import get_mongodb_client
from adapter.external.litellm import LiteLLMAdapter
from adapter.external.free_dictionary import FreeDictionaryAdapter

_llm = LiteLLMAdapter()
_dict_adapter = FreeDictionaryAdapter()
from services.lemma_extraction import _build_reduced_prompt as build_reduced_word_definition_prompt
from json_repair import repair_json
from services.dictionary_service import _build_full_prompt as build_word_definition_prompt


def get_random_vocabularies(count: int = 10) -> list[dict]:
    """MongoDBì—ì„œ ëœë¤í•˜ê²Œ vocabulary ë°ì´í„° ê°€ì ¸ì˜¤ê¸°."""
    client = get_mongodb_client()
    if not client:
        print("MongoDB ì—°ê²° ì‹¤íŒ¨")
        return []

    db = client['opad']

    # sentenceê°€ ìˆëŠ” ë°ì´í„°ë§Œ ê°€ì ¸ì˜¤ê¸°
    all_vocabs = list(db.vocabularies.find({
        'sentence': {'$exists': True, '$ne': None, '$ne': ''},
        'word': {'$exists': True, '$ne': None, '$ne': ''}
    }))

    if len(all_vocabs) < count:
        print(f"Warning: {len(all_vocabs)}ê°œë§Œ ìˆìŒ (ìš”ì²­: {count}ê°œ)")
        return all_vocabs

    return random.sample(all_vocabs, count)


async def test_hybrid_lookup(vocab: dict) -> dict:
    """í•˜ì´ë¸Œë¦¬ë“œ ì¡°íšŒ í…ŒìŠ¤íŠ¸ (LLM + API)."""
    word = vocab.get('word')
    sentence = vocab.get('sentence')
    language = vocab.get('language', 'German')

    result = {
        'word': word,
        'language': language,
        'sentence': sentence[:60] + '...' if len(sentence) > 60 else sentence,
    }

    # Step 1: Reduced LLM call
    prompt = build_reduced_word_definition_prompt(language, sentence, word)

    llm_start = time.time()
    try:
        content, stats = await _llm.call(
            messages=[{"role": "user", "content": prompt}],
            model="openai/gpt-4.1",
            max_tokens=500,
            temperature=0
        )
        llm_time = time.time() - llm_start
        llm_result = repair_json(content, return_objects=True)

        result['llm_time'] = llm_time
        result['llm_tokens'] = {
            'prompt': stats.prompt_tokens,
            'completion': stats.completion_tokens
        }
        result['llm_result'] = llm_result

        lemma = llm_result.get('lemma', word) if llm_result else word
    except Exception as e:
        result['llm_error'] = str(e)
        result['llm_time'] = time.time() - llm_start
        lemma = word

    # Step 2: Free Dictionary API call
    api_start = time.time()
    try:
        entries = await _dict_adapter.fetch(lemma, language)
        api_time = time.time() - api_start

        result['api_time'] = api_time
        if entries:
            entry = entries[0]
            senses = entry.get('senses', [])
            result['api_result'] = {
                'definition': senses[0].get('definition', '') if senses else '',
                'pos': entry.get('partOfSpeech'),
                'gender': None,
                'phonetics': None,
                'forms': None,
            }
        else:
            result['api_result'] = None
    except Exception as e:
        result['api_error'] = str(e)
        result['api_time'] = time.time() - api_start

    # Total time
    result['total_time'] = result.get('llm_time', 0) + result.get('api_time', 0)

    # Merged result
    if result.get('llm_result') and result.get('api_result'):
        result['source'] = 'hybrid'
        result['merged'] = {
            'lemma': result['llm_result'].get('lemma'),
            'definition': result['api_result'].get('definition'),
            'related_words': result['llm_result'].get('related_words'),
            'pos': result['api_result'].get('pos'),
            'gender': result['api_result'].get('gender'),
            'phonetics': result['api_result'].get('phonetics'),
            'level': result['llm_result'].get('level'),
            'forms': result['api_result'].get('forms'),
        }
    elif result.get('llm_result'):
        result['source'] = 'llm_only (API failed)'
    else:
        result['source'] = 'failed'

    return result


async def test_full_llm_lookup(vocab: dict) -> dict:
    """ê¸°ì¡´ Full LLM ì¡°íšŒ í…ŒìŠ¤íŠ¸ (ë¹„êµìš©)."""
    word = vocab.get('word')
    sentence = vocab.get('sentence')
    language = vocab.get('language', 'German')

    prompt = build_word_definition_prompt(language, sentence, word)

    start = time.time()
    try:
        content, stats = await _llm.call(
            messages=[{"role": "user", "content": prompt}],
            model="openai/gpt-4.1-mini",
            max_tokens=2000,
            temperature=0
        )
        elapsed = time.time() - start
        result = repair_json(content, return_objects=True)

        return {
            'time': elapsed,
            'tokens': {
                'prompt': stats.prompt_tokens,
                'completion': stats.completion_tokens
            },
            'result': result
        }
    except Exception as e:
        return {
            'time': time.time() - start,
            'error': str(e)
        }


async def run_comparison_test(vocabs: list[dict]):
    """í•˜ì´ë¸Œë¦¬ë“œ vs Full LLM ë¹„êµ í…ŒìŠ¤íŠ¸."""

    print(f"\n{'='*80}")
    print(f"í•˜ì´ë¸Œë¦¬ë“œ ì‚¬ì „ ì¡°íšŒ í…ŒìŠ¤íŠ¸ (LLM + Free Dictionary API)")
    print(f"í…ŒìŠ¤íŠ¸ ìˆ˜: {len(vocabs)}ê°œ")
    print(f"{'='*80}\n")

    hybrid_results = []
    full_llm_results = []

    for i, vocab in enumerate(vocabs):
        word = vocab.get('word')
        language = vocab.get('language', 'German')

        print(f"\n{'â”€'*80}")
        print(f"[{i+1}/{len(vocabs)}] '{word}' ({language})")
        print(f"ë¬¸ì¥: {vocab.get('sentence', '')[:70]}...")
        print(f"{'â”€'*80}")

        # Hybrid test
        print("\nğŸ“¦ [í•˜ì´ë¸Œë¦¬ë“œ] LLM + API:")
        hybrid = await test_hybrid_lookup(vocab)
        hybrid_results.append(hybrid)

        print(f"  LLM ì‹œê°„: {hybrid.get('llm_time', 0):.2f}s | í† í°: {hybrid.get('llm_tokens', {})}")
        print(f"  API ì‹œê°„: {hybrid.get('api_time', 0):.2f}s | ê²°ê³¼: {'âœ…' if hybrid.get('api_result') else 'âŒ'}")
        print(f"  ì´ ì‹œê°„: {hybrid.get('total_time', 0):.2f}s | ì†ŒìŠ¤: {hybrid.get('source')}")

        if hybrid.get('merged'):
            m = hybrid['merged']
            print(f"\n  ğŸ“ ë³‘í•© ê²°ê³¼:")
            print(f"     lemma: {m.get('lemma')}")
            print(f"     definition: {(m.get('definition') or '')[:60]}...")
            print(f"     pos: {m.get('pos')}")
            print(f"     gender: {m.get('gender')}")
            print(f"     phonetics: {m.get('phonetics')}")
            print(f"     level: {m.get('level')}")
            print(f"     related_words: {m.get('related_words')}")
            if m.get('forms'):
                print(f"     forms: {list(m.get('forms', {}).keys())}")

        # Full LLM test (ë¹„êµìš©)
        print("\nğŸ“¦ [Full LLM] ê¸°ì¡´ ë°©ì‹:")
        full = await test_full_llm_lookup(vocab)
        full_llm_results.append(full)

        print(f"  ì‹œê°„: {full.get('time', 0):.2f}s | í† í°: {full.get('tokens', {})}")
        if full.get('result'):
            r = full['result']
            print(f"     lemma: {r.get('lemma')}")
            print(f"     definition: {(r.get('definition') or '')[:60]}...")
            print(f"     pos: {r.get('pos')}")
            print(f"     gender: {r.get('gender')}")
            print(f"     level: {r.get('level')}")
            print(f"     related_words: {r.get('related_words')}")

        # ë¹„êµ
        time_diff = full.get('time', 0) - hybrid.get('total_time', 0)
        token_diff = full.get('tokens', {}).get('completion', 0) - hybrid.get('llm_tokens', {}).get('completion', 0)
        print(f"\n  âš¡ ì°¨ì´: ì‹œê°„ {time_diff:+.2f}s | í† í° {token_diff:+d}")

    # ìš”ì•½ í†µê³„
    print(f"\n\n{'='*80}")
    print("ğŸ“Š ìš”ì•½ í†µê³„")
    print(f"{'='*80}")

    # Hybrid stats
    hybrid_times = [r.get('total_time', 0) for r in hybrid_results]
    hybrid_llm_tokens = [r.get('llm_tokens', {}).get('completion', 0) for r in hybrid_results]
    hybrid_success = len([r for r in hybrid_results if r.get('source') == 'hybrid'])

    print(f"\n[í•˜ì´ë¸Œë¦¬ë“œ LLM+API]")
    print(f"  í‰ê·  ì‹œê°„: {sum(hybrid_times)/len(hybrid_times):.2f}s")
    print(f"  í‰ê·  LLM í† í°: {sum(hybrid_llm_tokens)/len(hybrid_llm_tokens):.0f}")
    print(f"  API ì„±ê³µë¥ : {hybrid_success}/{len(hybrid_results)} ({100*hybrid_success/len(hybrid_results):.0f}%)")

    # Full LLM stats
    full_times = [r.get('time', 0) for r in full_llm_results]
    full_tokens = [r.get('tokens', {}).get('completion', 0) for r in full_llm_results]

    print(f"\n[Full LLM ê¸°ì¡´ ë°©ì‹]")
    print(f"  í‰ê·  ì‹œê°„: {sum(full_times)/len(full_times):.2f}s")
    print(f"  í‰ê·  í† í°: {sum(full_tokens)/len(full_tokens):.0f}")

    # ì ˆê°ëŸ‰
    time_saved = sum(full_times)/len(full_times) - sum(hybrid_times)/len(hybrid_times)
    token_saved = sum(full_tokens)/len(full_tokens) - sum(hybrid_llm_tokens)/len(hybrid_llm_tokens)

    print(f"\n[ì ˆê°ëŸ‰]")
    print(f"  ì‹œê°„: {time_saved:.2f}s ({100*time_saved/(sum(full_times)/len(full_times)):.0f}% ì ˆê°)")
    print(f"  í† í°: {token_saved:.0f} ({100*token_saved/(sum(full_tokens)/len(full_tokens)):.0f}% ì ˆê°)")


def main():
    parser = argparse.ArgumentParser(description='í•˜ì´ë¸Œë¦¬ë“œ ì‚¬ì „ ì¡°íšŒ í…ŒìŠ¤íŠ¸')
    parser.add_argument('--count', type=int, default=10, help='í…ŒìŠ¤íŠ¸í•  ë‹¨ì–´ ìˆ˜ (ê¸°ë³¸: 10)')
    args = parser.parse_args()

    print("MongoDBì—ì„œ ë°ì´í„° ë¡œë”©...")
    vocabs = get_random_vocabularies(args.count)

    if not vocabs:
        print("í…ŒìŠ¤íŠ¸í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"{len(vocabs)}ê°œ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")

    asyncio.run(run_comparison_test(vocabs))


if __name__ == "__main__":
    main()
