# ì•„í‚¤í…ì²˜ ë¬¸ì„œ: 3-Service ë¶„ë¦¬

## ğŸ“Š í˜„ì¬ êµ¬ì¡° (Before)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Railway Container (ë‹¨ì¼)         â”‚
â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚  â”‚  Next.js     â”‚                       â”‚
â”‚  â”‚  (Port 3000) â”‚                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚         â”‚                               â”‚
â”‚         â”‚ spawn('python3', main.py)     â”‚
â”‚         â–¼                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚  â”‚ Python       â”‚                       â”‚
â”‚  â”‚ CrewAI ì‹¤í–‰   â”‚                       â”‚
â”‚  â”‚              â”‚                       â”‚
â”‚  â”‚ - status.json íŒŒì¼ ì“°ê¸°                â”‚
â”‚  â”‚ - MongoDBì— ì—…ë¡œë“œ                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                                         â”‚
â”‚  ë¬¸ì œì :                                  â”‚
â”‚  - Next.jsì™€ Pythonì´ ê°™ì€ ì»¨í…Œì´ë„ˆ          â”‚
â”‚  - ë¦¬ì†ŒìŠ¤ ê²½ìŸ (CPU/ë©”ëª¨ë¦¬)                  â”‚
â”‚  - í™•ì¥ ë¶ˆê°€ëŠ¥ (ë‘˜ ë‹¤ í•¨ê»˜ ìŠ¤ì¼€ì¼)             â”‚
â”‚  - ì¥ì•  ê²©ë¦¬ ë¶ˆê°€ (í•˜ë‚˜ ì£½ìœ¼ë©´ ì „ì²´)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### í˜„ì¬ íë¦„:
1. ì‚¬ìš©ìê°€ "Generate" í´ë¦­
2. Next.js `/api/generate` â†’ `spawn('python3', main.py)` ì‹¤í–‰
3. Pythonì´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ CrewAI ì‹¤í–‰
4. Pythonì´ `status.json` íŒŒì¼ì— ì§„í–‰ìƒí™© ê¸°ë¡
5. Next.jsê°€ `/api/status`ë¡œ í´ë§ (2ì´ˆë§ˆë‹¤)
6. ì™„ë£Œë˜ë©´ `/api/article`ë¡œ MongoDBì—ì„œ íŒŒì¼ ê°€ì ¸ì˜´

---

## ğŸ¯ ëª©í‘œ êµ¬ì¡° (After)

### ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```mermaid
graph TB
    Web[Web<br/>Next.js] -->|HTTP| API[API<br/>FastAPI]
    API -->|RPUSH| Redis[(Redis<br/>Queue + Status)]
    Redis -->|BLPOP| Worker[Worker<br/>Python]
    Worker -->|Execute| CrewAI[CrewAI]
    Worker -->|Save| MongoDB[(MongoDB<br/>Article + Vocabulary)]
    
    API -.->|SET/GET| Redis
    Worker -.->|SET| Redis
    
    API -.->|utils/llm.py<br/>utils/prompts.py| OpenAI
    
    Web -->|HTTP<br/>Proxy| API
    API -->|Save/Query| MongoDB
    
    style Web fill:#2196F3
    style API fill:#2196F3
    style Worker fill:#2196F3
    style CrewAI fill:#10a37f
    style Redis fill:#dc382d
    style MongoDB fill:#13aa52
    style OpenAI fill:#10a37f
    
    linkStyle 0 stroke:#4a90e2,stroke-width:2px,color:#4a90e2
    linkStyle 1 stroke:#4a90e2,stroke-width:2px,color:#4a90e2
    linkStyle 2 stroke:#4a90e2,stroke-width:2px,color:#4a90e2
    linkStyle 5 stroke:#ff9500,stroke-width:2px,color:#ff9500
    linkStyle 6 stroke:#13aa52,stroke-width:2px,color:#13aa52
    linkStyle 7 stroke:#9c27b0,stroke-width:2px,color:#9c27b0
    linkStyle 8 stroke:#9c27b0,stroke-width:2px,color:#9c27b0
```

### Article Generation íë¦„

```mermaid
sequenceDiagram
    participant Web
    participant API
    participant Redis
    participant Worker
    participant CrewAI
    participant MongoDB
    
    Web->>API: POST /articles/generate
    API->>MongoDB: Check duplicates
    API->>MongoDB: Save article metadata
    API->>Redis: RPUSH job
    API-->>Web: Return job_id + article_id
    
    Worker->>Redis: BLPOP
    Redis-->>Worker: job_data
    
    Worker->>CrewAI: Execute crew.kickoff()
    CrewAI-->>Worker: Return article
    
    Worker->>MongoDB: Save article content
    Worker->>Redis: Update status (completed)
```

**íŠ¹ì§•:**
- **ì‹¤ì‹œê°„ ì‘ë‹µ**: ì‚¬ìš©ìê°€ ë‹¨ì–´ë¥¼ í´ë¦­í•˜ë©´ ì¦‰ì‹œ ì •ì˜ ë°˜í™˜ (ë¹„ë™ê¸° í ì‚¬ìš© ì•ˆ í•¨)
- **í”„ë¡ì‹œ íŒ¨í„´**: Next.js API routeê°€ FastAPIë¡œ ìš”ì²­ì„ í”„ë¡ì‹œ
- **ê³µí†µ ìœ í‹¸ ì‚¬ìš©**: `utils/llm.py`ì™€ `utils/prompts.py`ë¡œ ì¬ì‚¬ìš© ê°€ëŠ¥í•œ êµ¬ì¡°
- **ì—ëŸ¬ ì²˜ë¦¬**: `get_llm_error_response()`ë¡œ ì¼ê´€ëœ ì—ëŸ¬ ì‘ë‹µ

### ì„œë¹„ìŠ¤ ê°„ í†µì‹ 

| From | To | Method | Purpose |
|------|-----|--------|---------|
| **Web** | **API** | HTTP | Article ìƒì„±, Job enqueue, Token usage ì¡°íšŒ |
| **Web** | **Next.js API** | HTTP | Dictionary API ìš”ì²­ (í”„ë¡ì‹œ), Vocabulary CRUD ìš”ì²­ (í”„ë¡ì‹œ), Dictionary Stats ìš”ì²­ (í”„ë¡ì‹œ) |
| **Next.js API** | **API** | HTTP | Dictionary API í”„ë¡ì‹œ ìš”ì²­, Vocabulary CRUD í”„ë¡ì‹œ ìš”ì²­, Dictionary Stats í”„ë¡ì‹œ ìš”ì²­ |
| **API** | **MongoDB** | (via utils.mongodb) | ì¤‘ë³µ ì²´í¬, Article metadata ì €ì¥/ì¡°íšŒ, Vocabulary ì €ì¥/ì¡°íšŒ, Token usage ì €ì¥/ì¡°íšŒ |
| **API** | **Redis** | `RPUSH` | Jobì„ íì— ì¶”ê°€ |
| **API** | **Redis** | `SET/GET` | Job ìƒíƒœ ì €ì¥/ì¡°íšŒ (ê³µí†µ ëª¨ë“ˆ `api.job_queue` ì‚¬ìš©) |
| **API** | **LLM** | HTTP (via utils.llm) | Dictionary APIìš© LLM í˜¸ì¶œ (lemma, definition, related_words) + Token tracking |
| **API** | **API** | Internal | Token usage endpoints (`/usage/me`, `/usage/articles/{id}`) |
| **Worker** | **Redis** | `BLPOP` | Jobì„ íì—ì„œ êº¼ëƒ„ (blocking) |
| **Worker** | **Redis** | `SET` | Job ìƒíƒœ ì—…ë°ì´íŠ¸ (ê³µí†µ ëª¨ë“ˆ `api.job_queue` ì‚¬ìš©) |
| **Worker** | **CrewAI** | Function Call | Article ìƒì„± |
| **Worker** | **MongoDB** | (via utils.mongodb) | Article content ì €ì¥, Token usage ì €ì¥ |

**ì°¸ê³ **: APIì™€ Worker ëª¨ë‘ `api.job_queue` ëª¨ë“ˆì„ í†µí•´ Redisì— ì ‘ê·¼í•©ë‹ˆë‹¤. MongoDB ì ‘ê·¼ì€ `utils.mongodb` ëª¨ë“ˆì„ í†µí•´ í•©ë‹ˆë‹¤.

### Redis ë°ì´í„° êµ¬ì¡°

#### 1. Job Queue (List) - `opad:jobs`

**ìš©ë„**: Workerê°€ ì²˜ë¦¬í•  jobë“¤ì„ FIFO ìˆœì„œë¡œ ì €ì¥

```
Queue: opad:jobs (List)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [oldest] â† ... â† [newest]       â”‚
â”‚    â†‘                    â†‘       â”‚
â”‚  BLPOP              RPUSH       â”‚
â”‚ (Worker)             (API)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ë°ì´í„° í˜•ì‹**:
```json
{
  "job_id": "uuid",
  "article_id": "uuid",
  "inputs": {
    "language": "Korean",
    "level": "B1",
    "length": "300",
    "topic": "Climate Change"
  },
  "created_at": "2025-01-08T12:34:56.789Z"
}
```

#### 2. Job Status (String) - `opad:job:{job_id}`

**ìš©ë„**: ê° jobì˜ í˜„ì¬ ìƒíƒœì™€ ì§„í–‰ë¥  ì¶”ì 

**TTL**: 24ì‹œê°„ (ìë™ ì‚­ì œ)

**ë°ì´í„° í˜•ì‹**:
```json
{
  "id": "job-uuid",
  "article_id": "article-uuid",
  "status": "running",
  "progress": 45,
  "message": "Adapting article...",
  "error": null,
  "created_at": "2025-01-08T12:34:56.789Z",
  "updated_at": "2025-01-08T12:35:12.345Z"
}
```

**ì ‘ê·¼ íŒ¨í„´**:
- **API**: ìƒíƒœ ì´ˆê¸°í™” (queued), ì¡°íšŒ (GET)
- **Worker**: ìƒíƒœ ì—…ë°ì´íŠ¸ (running, completed, failed)
- **Progress Listener**: ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (0-100%) - CrewAI ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆë¥¼ í†µí•´ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸

---

## ğŸ”‘ í•µì‹¬ ê°œë…

### 1. **ë¹„ë™ê¸° ì‘ì—… ì²˜ë¦¬ (Async Job Processing)**
- **ë¬¸ì œ**: CrewAI ì‹¤í–‰ì€ 2-5ë¶„ ê±¸ë¦¼ â†’ HTTP ìš”ì²­ì´ íƒ€ì„ì•„ì›ƒ
- **í•´ê²°**: Job Queue íŒ¨í„´
  - ìš”ì²­ ì¦‰ì‹œ `jobId` ë°˜í™˜
  - ì‹¤ì œ ì‘ì—…ì€ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì²˜ë¦¬
  - í´ë¼ì´ì–¸íŠ¸ëŠ” job ìƒíƒœë¥¼ í´ë§

### 2. **ì„œë¹„ìŠ¤ ë¶„ë¦¬ (Service Separation)**
- **ì›ì¹™**: "í•œ ì»¨í…Œì´ë„ˆ = í•œ ì—­í• "
- **ì¥ì **:
  - ë…ë¦½ì  ìŠ¤ì¼€ì¼ë§ (workerë§Œ ëŠ˜ë¦¬ë©´ ë¨)
  - ì¥ì•  ê²©ë¦¬ (worker ì£½ì–´ë„ web/apiëŠ” ì •ìƒ)
  - ë°°í¬ ë¶„ë¦¬ (apië§Œ ìˆ˜ì •í•´ë„ worker ì˜í–¥ ì—†ìŒ)

### 3. **Job Queue (Redis)**
- **ì—­í• **: ì‘ì—… ìš”ì²­ì„ íì— ë„£ê³ , workerê°€ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬
- **ìƒíƒœ**: `queued` â†’ `running` â†’ `completed` / `failed`
- **ì¥ì **: ë¶€í•˜ ë¶„ì‚°, ì¬ì‹œë„ ê°€ëŠ¥, ìš°ì„ ìˆœìœ„ ì„¤ì • ê°€ëŠ¥

### 4. **ë°ì´í„° ì €ì¥ì†Œ**

#### MongoDB: Article Storage
- **Article metadata ë° content ì €ì¥** (`articles` ì»¬ë ‰ì…˜)
  - ì¤‘ë³µ ì²´í¬ (24ì‹œê°„ ë‚´ ë™ì¼ ì…ë ¥ íŒŒë¼ë¯¸í„°)
  - Article ì¡°íšŒ ë° ë¦¬ìŠ¤íŠ¸

- **Vocabulary ì €ì¥** (`vocabularies` ì»¬ë ‰ì…˜)
  - ë‹¨ì–´, lemma, ì •ì˜, ë¬¸ì¥ ì»¨í…ìŠ¤íŠ¸ ì €ì¥
  - `related_words` ë°°ì—´ í¬í•¨ (ë¶„ë¦¬ ë™ì‚¬ ë“± ë³µì¡í•œ ì–¸ì–´ êµ¬ì¡° ì§€ì›)
  - Articleë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ê´€ë¦¬

- **Token Usage ì¶”ì ** (`token_usage` ì»¬ë ‰ì…˜)
  - LLM API í˜¸ì¶œ ì‹œ í† í° ì‚¬ìš©ëŸ‰ ë° ë¹„ìš© ì¶”ì 
  - ì‚¬ìš©ìë³„, ì‘ì—…ë³„ (dictionary_search, article_generation) ì§‘ê³„
  - ì¼ë³„ ì‚¬ìš©ëŸ‰ í†µê³„ ë° ë¹„ìš© ë¶„ì„
  
**Article Status** (MongoDB, ì˜êµ¬ ì €ì¥):
- `running`: Article ìƒì„± ì‹œ ì´ˆê¸° ìƒíƒœ (ì²˜ë¦¬ ì¤‘)
- `completed`: Article ìƒì„± ì™„ë£Œ
- `failed`: Article ìƒì„± ì‹¤íŒ¨
- `deleted`: Article ì‚­ì œ (soft delete)

**Status Flow:**
```
ìƒì„± ì‹œ: running
   â†“
ì™„ë£Œ: completed
ì‹¤íŒ¨: failed
```

#### Redis: Job Queue & Status
- **Queue**: `opad:jobs` (List) - Workerê°€ ì²˜ë¦¬í•  jobë“¤ì„ FIFO ìˆœì„œë¡œ ì €ì¥
- **Status**: `opad:job:{job_id}` (String, 24h TTL) - Jobì˜ ì‹¤ì‹œê°„ ìƒíƒœ ì¶”ì 

**Job Status** (Redis, 24ì‹œê°„ TTL):
- `queued`: Jobì´ íì— ì¶”ê°€ë¨ (Workerê°€ ì•„ì§ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ)
- `running`: Workerê°€ Jobì„ ì²˜ë¦¬ ì¤‘
- `completed`: Job ì²˜ë¦¬ ì™„ë£Œ
- `failed`: Job ì²˜ë¦¬ ì‹¤íŒ¨

**Status Flow:**
```
queued â†’ running â†’ completed / failed
```

**Article Status vs Job Status:**
- **Article Status (MongoDB)**: Articleì˜ ìµœì¢… ìƒíƒœ (ì˜êµ¬ ì €ì¥)
- **Job Status (Redis)**: Job ì²˜ë¦¬ì˜ ì‹¤ì‹œê°„ ìƒíƒœ (24ì‹œê°„ í›„ ìë™ ì‚­ì œ)
- Articleì€ `running` ìƒíƒœë¡œ ìƒì„±ë˜ê³ , Jobì´ ì™„ë£Œë˜ë©´ `completed` ë˜ëŠ” `failed`ë¡œ ì—…ë°ì´íŠ¸ë¨

---

## ğŸ’° Token Usage Tracking

### Overview
The system tracks LLM API token usage and costs for all API calls, enabling cost monitoring, user billing, and usage analytics.

### Architecture

#### 1. LLM Utility Module (`utils/llm.py`)
Provider-agnostic LLM API calls using LiteLLM with automatic token tracking.

**Functions**:
- `call_llm_with_tracking()`: Makes LLM API calls and returns content + token statistics
- `parse_json_from_content()`: Parses JSON from LLM responses (handles markdown code blocks)
- `get_llm_error_response()`: Converts LLM exceptions to HTTP status codes

**TokenUsageStats Dataclass**:
```python
@dataclass
class TokenUsageStats:
    model: str              # Model name (e.g., "gpt-4.1-mini")
    prompt_tokens: int      # Input tokens
    completion_tokens: int  # Output tokens
    total_tokens: int       # Total tokens used
    estimated_cost: float   # Cost in USD (calculated by LiteLLM)
    provider: str | None    # Provider name (openai, anthropic, google)
```

**Supported Providers** (via LiteLLM):
- OpenAI: `"gpt-4.1-mini"`, `"gpt-4.1"`
- Anthropic: `"anthropic/claude-4.5-sonnet"`
- Google: `"gemini/gemini-2.0-flash"`

**Example Usage**:
```python
from utils.llm import call_llm_with_tracking, TokenUsageStats

content, stats = await call_llm_with_tracking(
    messages=[{"role": "user", "content": "Hello"}],
    model="gpt-4.1-mini",
    max_tokens=200
)

# stats.model = "gpt-4.1-mini"
# stats.prompt_tokens = 8
# stats.completion_tokens = 12
# stats.estimated_cost = 0.000015
```

#### 2. MongoDB Storage (`utils/mongodb.py`)

**save_token_usage()**: Save token usage record
```python
def save_token_usage(
    user_id: str,
    operation: str,  # "dictionary_search" | "article_generation"
    model: str,
    prompt_tokens: int,
    completion_tokens: int,
    estimated_cost: float,
    article_id: Optional[str] = None,
    metadata: Optional[dict] = None
) -> Optional[str]:
    """Save token usage record to MongoDB."""
```

**get_user_token_summary()**: Get user's token usage summary
```python
def get_user_token_summary(user_id: str, days: int = 30) -> dict:
    """
    Returns:
    {
        'total_tokens': int,
        'total_cost': float,
        'by_operation': {
            'operation_type': {'tokens': int, 'cost': float, 'count': int}
        },
        'daily_usage': [
            {'date': 'YYYY-MM-DD', 'tokens': int, 'cost': float}
        ]
    }
    """
```

**get_article_token_usage()**: Get token usage for specific article
```python
def get_article_token_usage(article_id: str) -> list[dict]:
    """Returns all token usage records for an article."""
```

#### 3. Token Usage Collection Schema (MongoDB)

```json
{
  "_id": "uuid",
  "user_id": "uuid",
  "operation": "dictionary_search | article_generation",
  "model": "string",
  "prompt_tokens": 100,
  "completion_tokens": 50,
  "total_tokens": 150,
  "estimated_cost": 0.00025,
  "article_id": "uuid (optional)",
  "metadata": {
    "query": "...",
    "language": "..."
  },
  "created_at": "datetime"
}
```

**Indexes**:
- `(user_id, created_at)`: User usage queries (descending)
- `article_id`: Article-specific queries (sparse)
- `created_at`: Time-based queries (descending)
- `(operation, created_at)`: Operation-type queries

### Integration

#### Dictionary API (`src/api/routes/dictionary.py`)

```python
@router.post("/search", response_model=SearchResponse)
async def search_word(request: SearchRequest, current_user: User = Depends(get_current_user_required)):
    # Build prompt
    prompt = build_word_definition_prompt(
        language=request.language,
        sentence=request.sentence,
        word=request.word
    )

    # Call LLM with tracking
    content, stats = await call_llm_with_tracking(
        messages=[{"role": "user", "content": prompt}],
        model="gpt-4.1-mini",
        max_tokens=200
    )

    # Log token usage
    logger.info("Token usage for dictionary search", extra=stats.to_dict())

    # Save to database (Phase 2)
    save_token_usage(
        user_id=current_user.id,
        operation="dictionary_search",
        model=stats.model,
        prompt_tokens=stats.prompt_tokens,
        completion_tokens=stats.completion_tokens,
        estimated_cost=stats.estimated_cost,
        metadata={"query": request.word, "language": request.language}
    )

    # Parse and return response
    result = parse_json_from_content(content)
    return SearchResponse(**result)
```

#### Token Usage API Endpoints (`src/api/routes/usage.py`)

**GET /usage/me**: Get current user's token usage summary
```python
@router.get("/me", response_model=TokenUsageSummary)
async def get_my_usage(
    days: int = Query(default=30, ge=1, le=365),
    current_user: User = Depends(get_current_user_required)
):
    # Get aggregated summary from MongoDB
    summary = get_user_token_summary(user_id=current_user.id, days=days)

    # Convert to response models
    by_operation = {
        op_name: OperationUsage(**op_data)
        for op_name, op_data in summary.get('by_operation', {}).items()
    }
    daily_usage = [
        DailyUsage(**day) for day in summary.get('daily_usage', [])
    ]

    return TokenUsageSummary(
        total_tokens=summary.get('total_tokens', 0),
        total_cost=summary.get('total_cost', 0.0),
        by_operation=by_operation,
        daily_usage=daily_usage
    )
```

**GET /usage/articles/{article_id}**: Get token usage for specific article
```python
@router.get("/articles/{article_id}", response_model=list[TokenUsageRecord])
async def get_article_usage(
    article_id: str,
    current_user: User = Depends(get_current_user_required)
):
    # Verify article ownership
    article = get_article(article_id)
    if not article:
        raise HTTPException(status_code=404, detail="Article not found")
    if article.get('user_id') != current_user.id:
        raise HTTPException(status_code=403, detail="You don't have permission")

    # Get all usage records for article
    usage_records = get_article_token_usage(article_id)

    return [TokenUsageRecord(**record) for record in usage_records]
```

### Token Usage Flow Diagram

```mermaid
sequenceDiagram
    participant User
    participant WebUI as Web UI
    participant API as FastAPI
    participant MongoDB
    participant LLM as LLM Provider

    Note over User,LLM: Dictionary Search with Token Tracking
    User->>WebUI: Click word
    WebUI->>API: POST /dictionary/search
    API->>LLM: Call LLM API
    LLM-->>API: Response + usage stats
    API->>MongoDB: save_token_usage()
    API-->>WebUI: Definition response

    Note over User,MongoDB: Usage Summary Retrieval
    User->>WebUI: View usage page
    WebUI->>API: GET /usage/me?days=30
    API->>MongoDB: get_user_token_summary()
    MongoDB-->>API: Aggregated summary
    API-->>WebUI: TokenUsageSummary
    WebUI-->>User: Display usage charts

    Note over User,MongoDB: Article Usage Details
    User->>WebUI: View article usage
    WebUI->>API: GET /usage/articles/{id}
    API->>MongoDB: get_article_token_usage()
    MongoDB-->>API: Usage records
    API-->>WebUI: List of TokenUsageRecord
    WebUI-->>User: Display usage details
```

### Future Enhancements

**Phase 1** (Completed):
- âœ… LiteLLM integration with token tracking
- âœ… TokenUsageStats dataclass
- âœ… MongoDB storage functions
- âœ… Dictionary API integration with logging

**Phase 2** (Completed):
- âœ… Database storage of token usage records
- âœ… User token summary endpoint
- âœ… Article token usage tracking

**Phase 3** (Completed):
- âœ… API endpoints for token usage (`/usage/me`, `/usage/articles/{id}`)
- âœ… Authentication and authorization for usage endpoints
- âœ… Usage summary with daily breakdown and operation filtering

**Phase 4** (Planned):
- CrewAI article generation token tracking
- Usage analytics dashboard (Frontend)
- Cost alerts and limits
- Per-user billing reports

---

## ğŸ“š Vocabulary-Aware Article Generation

### Overview
The system now supports vocabulary-aware article generation, where CrewAI adjusts content difficulty based on words the user has already learned.

### Vocabulary Features

#### 1. Dictionary API - Word Definition
- **POST /dictionary/search**: Get word definition and lemma using OpenAI API
- **Returns**: lemma, definition, and related_words (for complex structures like separable verbs)
- **Auth**: Required (JWT) to prevent API abuse

#### 2. Vocabulary Storage
- **POST /dictionary/vocabulary**: Add a word to user's vocabulary
- **GET /dictionary/vocabularies**: Get aggregated vocabulary grouped by lemma with counts
- **DELETE /dictionary/vocabularies/{id}**: Delete a vocabulary word
- **Auth**: All vocabulary operations require authentication and are user-specific

#### 3. Article-Specific Vocabularies
- **GET /articles/{article_id}/vocabularies**: Get all vocabularies for a specific article
- **Response**: List of VocabularyResponse objects with word, lemma, definition, context, and metadata
- **Auth**: Users can only access vocabularies from their own articles

### Data Model

#### Vocabulary Collection (MongoDB)
```json
{
  "_id": "ObjectId",
  "article_id": "uuid",
  "user_id": "uuid",
  "word": "string",              // Original word clicked
  "lemma": "string",             // Dictionary form
  "definition": "string",        // Word definition
  "sentence": "string",          // Sentence context
  "language": "string",
  "related_words": ["string"],   // All forms in sentence (e.g., verbs with particles)
  "span_id": "string",           // Span ID from markdown for linking
  "created_at": "datetime",
  "pos": "string",               // Part of speech (noun, verb, adjective, etc.)
  "gender": "string",            // Grammatical gender (der/die/das for German, le/la for French, etc.)
  "conjugations": {              // Verb conjugations (null for non-verbs)
    "present": "string",
    "past": "string",
    "perfect": "string"
  },
  "level": "string"              // CEFR level (A1, A2, B1, B2, C1, C2)
}
```

**New Grammatical Metadata Fields:**
- `pos`: Part of speech classification (noun, verb, adjective, adverb, preposition, etc.)
- `gender`: Grammatical gender for nouns in gendered languages (German: der/die/das, French: le/la, Spanish: el/la). Null for non-gendered languages.
- `conjugations`: Verb conjugation forms across tenses (present, past, perfect). Null for non-verbs.
- `level`: CEFR difficulty level (A1-C2) for vocabulary tracking and adaptive learning.

#### VocabularyCount Model (Aggregated Response)
- Groups vocabularies by lemma
- Returns count of how many times a lemma appears across articles
- Includes most recent definition and example sentence
- Lists all article_ids where lemma appears
- Includes grammatical metadata (pos, gender, conjugations, level) from most recent entry

#### API Model Enhancements

**Conjugations.__bool__()** (`src/api/models.py:18-20`):
- Enables truthiness checking: `if conjugations:` returns False when all fields (present, past, perfect) are None
- Simplifies validation logic by treating empty Conjugations as falsy
- Backend can check conjugation presence without explicit null checks

**VocabularyRequest.field_validator** (`src/api/models.py:106-116`):
- Automatic conversion from Conjugations model to dict before database storage
- Returns None if conjugations object is empty (using `__bool__` check)
- Handles both dict and Conjugations input types
- Prevents storing empty conjugation objects in MongoDB

### Vocabulary-Aware Generation Flow
1. User saves vocabulary words from articles (POST /dictionary/vocabulary)
2. Words stored with article context (sentence, span_id)
3. When generating new article, worker retrieves user's vocabulary list
4. CrewAI receives vocabulary list as constraint for content difficulty
5. Generated article uses different words/complexity for learned vocabulary
6. User can access article-specific vocabularies (GET /articles/{id}/vocabularies)

### Authentication
All vocabulary endpoints require JWT authentication. Users can only:
- Add/delete their own vocabulary
- View their own vocabulary lists
- Access vocabularies from their own articles

---

## ğŸ“ ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
opad/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/              # API ì„œë¹„ìŠ¤ (FastAPI)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py       # FastAPI ì•± ì§„ì…ì 
â”‚   â”‚   â”œâ”€â”€ models.py     # Pydantic ëª¨ë¸ (Article, Job)
â”‚   â”‚   â”œâ”€â”€ routes/       # API ì—”ë“œí¬ì¸íŠ¸
â”‚   â”‚   â”‚   â”œâ”€â”€ articles.py
â”‚   â”‚   â”‚   â”œâ”€â”€ jobs.py
â”‚   â”‚   â”‚   â”œâ”€â”€ health.py
â”‚   â”‚   â”‚   â”œâ”€â”€ endpoints.py
â”‚   â”‚   â”‚   â”œâ”€â”€ stats.py
â”‚   â”‚   â”‚   â””â”€â”€ dictionary.py  # Dictionary API (word definition)
â”‚   â”‚   â””â”€â”€ job_queue.py  # Redis í ê´€ë¦¬
â”‚   â”‚
â”‚   â”œâ”€â”€ worker/           # Worker ì„œë¹„ìŠ¤ (Python)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py       # Worker ì§„ì…ì 
â”‚   â”‚   â””â”€â”€ processor.py  # Job ì²˜ë¦¬ ë¡œì§
â”‚   â”‚
â”‚   â”œâ”€â”€ web/              # Web ì„œë¹„ìŠ¤ (Next.js)
â”‚   â”‚   â”œâ”€â”€ app/          # Next.js App Router
â”‚   â”‚   â”‚   â”œâ”€â”€ api/      # API Routes (í”„ë¡ì‹œ)
â”‚   â”‚   â”‚   â”œâ”€â”€ articles/ # Article pages
â”‚   â”‚   â”‚   â”œâ”€â”€ vocabulary/ # Vocabulary pages
â”‚   â”‚   â”‚   â””â”€â”€ page.tsx  # ë©”ì¸ í˜ì´ì§€
â”‚   â”‚   â”œâ”€â”€ components/   # React ì»´í¬ë„ŒíŠ¸
â”‚   â”‚   â”‚   â”œâ”€â”€ ArticleCard.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ EmptyState.tsx      # Reusable empty state
â”‚   â”‚   â”‚   â”œâ”€â”€ ErrorAlert.tsx      # Reusable error alert
â”‚   â”‚   â”‚   â”œâ”€â”€ MarkdownViewer.tsx
â”‚   â”‚   â”‚   â””â”€â”€ VocabularyList.tsx
â”‚   â”‚   â”œâ”€â”€ hooks/        # Custom React hooks
â”‚   â”‚   â”‚   â”œâ”€â”€ useAsyncFetch.ts    # Generic fetch with loading/error
â”‚   â”‚   â”‚   â”œâ”€â”€ usePagination.ts    # Pagination calculations
â”‚   â”‚   â”‚   â”œâ”€â”€ useStatusPolling.ts # Job status polling
â”‚   â”‚   â”‚   â””â”€â”€ useVocabularyDelete.ts # Vocabulary deletion
â”‚   â”‚   â”œâ”€â”€ lib/          # Frontend utilities
â”‚   â”‚   â”‚   â”œâ”€â”€ api.ts           # fetchWithAuth, parseErrorResponse
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.ts          # Auth utilities
â”‚   â”‚   â”‚   â”œâ”€â”€ formatters.ts    # Date formatting utilities
â”‚   â”‚   â”‚   â””â”€â”€ styleHelpers.ts  # CEFR color/label helpers
â”‚   â”‚   â”œâ”€â”€ types/        # TypeScript type definitions
â”‚   â”‚   â”œâ”€â”€ tailwind.config.ts # Tailwind config with safelist
â”‚   â”‚   â””â”€â”€ package.json
â”‚   â”‚
â”‚   â”œâ”€â”€ opad/             # CrewAI ë¡œì§ (ê³µìœ )
â”‚   â”‚   â”œâ”€â”€ crew.py
â”‚   â”‚   â””â”€â”€ main.py
â”‚   â”‚
â”‚   â””â”€â”€ utils/            # ê³µí†µ ìœ í‹¸ë¦¬í‹° (ê³µìœ )
â”‚       â”œâ”€â”€ mongodb.py    # MongoDB ì—°ê²° ë° ì‘ì—…
â”‚       â”œâ”€â”€ logging.py    # Structured logging ì„¤ì •
â”‚       â”œâ”€â”€ llm.py        # OpenAI API ê³µí†µ í•¨ìˆ˜
â”‚       â””â”€â”€ prompts.py    # LLM í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
â”‚
â””â”€â”€ Dockerfile.*          # ì„œë¹„ìŠ¤ë³„ Dockerfile (ì´ìŠˆ #9)
```

### ì„œë¹„ìŠ¤ êµ¬ë¶„
| í´ë” | ì—­í•  | ëŸ°íƒ€ì„ | í¬íŠ¸ |
|------|------|--------|------|
| `src/api/` | CRUD + Job enqueue + Dictionary API | Python (FastAPI) | 8001 (default) |
| `src/worker/` | CrewAI ì‹¤í–‰ | Python | - |
| `src/web/` | UI | Node.js (Next.js) | 3000 |
| `src/opad/` | CrewAI ë¡œì§ (ê³µìœ ) | - | - |
| `src/utils/` | ê³µí†µ ìœ í‹¸ (ê³µìœ ) | - | - |

---

## ğŸ”‘ ê³µí†µ ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ

### LLM ìœ í‹¸ë¦¬í‹° (`utils/llm.py`)
Provider-agnostic LLM API í˜¸ì¶œ ë° í† í° ì¶”ì ì„ ìœ„í•œ ê³µí†µ í•¨ìˆ˜ë“¤ (LiteLLM ê¸°ë°˜):

- **`call_llm_with_tracking()`**: LLM API í˜¸ì¶œ + í† í° ì‚¬ìš©ëŸ‰ ì¶”ì  (ë²”ìš© í•¨ìˆ˜)
  - ë°˜í™˜ê°’: `(content: str, stats: TokenUsageStats)`
  - OpenAI, Anthropic, Google ë“± ë‹¤ì–‘í•œ í”„ë¡œë°”ì´ë” ì§€ì›
  - ìë™ ë¹„ìš© ê³„ì‚° (LiteLLM ë‚´ì¥ ê°€ê²© ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš©)
- **`TokenUsageStats`**: í† í° ì‚¬ìš©ëŸ‰ í†µê³„ dataclass
  - í•„ë“œ: `model`, `prompt_tokens`, `completion_tokens`, `total_tokens`, `estimated_cost`, `provider`
- **`parse_json_from_content()`**: LLM ì‘ë‹µì—ì„œ JSON íŒŒì‹± (ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›)
  - ì¼ë°˜ JSON, ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ (```json), í…ìŠ¤íŠ¸ ë‚´ JSON ì¶”ì¶œ ì§€ì›
- **`get_llm_error_response()`**: LLM ê´€ë ¨ ì˜ˆì™¸ë¥¼ HTTP ìƒíƒœ ì½”ë“œë¡œ ë³€í™˜

**ì‚¬ìš© ì˜ˆì‹œ:**
```python
from utils.llm import call_llm_with_tracking, parse_json_from_content

# LLM í˜¸ì¶œ + í† í° ì¶”ì 
content, stats = await call_llm_with_tracking(
    messages=[{"role": "user", "content": "Hello"}],
    model="gpt-4.1-mini",
    max_tokens=200
)

# í† í° ì‚¬ìš©ëŸ‰ ë¡œê¹…
logger.info("Token usage", extra=stats.to_dict())

# JSON íŒŒì‹±
result = parse_json_from_content(content)
```

**ì§€ì› í”„ë¡œë°”ì´ë”** (LiteLLM):
- OpenAI: `"gpt-4.1-mini"`, `"gpt-4.1"`
- Anthropic: `"anthropic/claude-4.5-sonnet"`
- Google: `"gemini/gemini-2.0-flash"`

### í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (`utils/prompts.py`)
ì¬ì‚¬ìš© ê°€ëŠ¥í•œ LLM í”„ë¡¬í”„íŠ¸ ë¹Œë” í•¨ìˆ˜ë“¤:

- **`build_word_definition_prompt()`**: Dictionary APIìš© í”„ë¡¬í”„íŠ¸ ìƒì„± (lemma ë° definition ì¶”ì¶œ)

**ì‚¬ìš© ì˜ˆì‹œ:**
```python
from utils.prompts import build_word_definition_prompt

prompt = build_word_definition_prompt(
    language="German",
    sentence="Diese groÃŸe Spanne hÃ¤ngt von mehreren Faktoren ab.",
    word="hÃ¤ngt"
)
```

---

## ğŸ“¡ Dynamic Endpoint Discovery

### Tag-Based Endpoint Grouping

The `/endpoints` endpoint dynamically generates an HTML page listing all registered API routes, grouped by their tags. This system requires no code changes when new routes are addedâ€”they automatically appear in the listing.

**Endpoint**: `GET /endpoints`

**File**: `src/api/routes/endpoints.py`

**How It Works**:

1. **Route Introspection**: Scans `app.routes` to collect all routes with methods and paths
2. **Tag Extraction**: Reads tags from route definitions (e.g., `tags=["articles"]`, `tags=["usage"]`)
3. **Dynamic Grouping**: Groups endpoints by tag using `group_endpoints_by_tag()`
4. **HTML Generation**: Renders grouped endpoints as styled HTML page

**Helper Functions**:

- **`group_endpoints_by_tag(endpoints)`**: Groups endpoints by tag (first tag if multiple), returns `dict[tag, list[endpoints]]`
  - Uses `defaultdict(list)` to avoid KeyError
  - Filters out `EXCLUDED_TAGS` (e.g., "meta")
  - Sorts endpoints within each group by `(path, method)`
  - Assigns "other" tag if endpoint has no tags

- **`get_sorted_tags(grouped)`**: Returns alphabetically sorted tag list with "other" at end

- **`format_endpoint(ep)`**: Formats single endpoint as HTML with method badge, path, and summary

- **`format_tag_title(tag)`**: Converts tag name to display title (e.g., "articles" â†’ "Articles Endpoints")

**Configuration**:

```python
# src/api/routes/endpoints.py:13-14
EXCLUDED_TAGS = {"meta"}  # Tags to hide from listing
EXCLUDED_PATHS = {"/docs", "/openapi.json", "/redoc"}  # Paths to skip
```

**Example Route Definition**:

```python
# src/api/routes/usage.py
router = APIRouter(tags=["usage"])  # Tag used for grouping

@router.get("/me", summary="Get current user's token usage summary")
async def get_my_usage(...):
    """Detailed description..."""
```

**Benefits**:

- **Zero-maintenance**: New routes automatically appear in listing
- **Tag-based organization**: Routes grouped by domain (articles, usage, dictionary)
- **Clean HTML output**: Color-coded HTTP methods (GET=blue, POST=green, DELETE=red)
- **No hardcoding**: Eliminates manual endpoint lists

**Usage**:
Visit `/endpoints` in browser to see all available API routes grouped by tag.

---

## ğŸ“¡ Dictionary API

### Word Definition Endpoint

**Endpoint**: `POST /dictionary/search`

**ëª©ì **: ë¬¸ì¥ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ë‹¨ì–´ì˜ lemma, ì •ì˜ ë° ë¬¸ë²•ì  ë©”íƒ€ë°ì´í„°ë¥¼ ì¶”ì¶œ

**ìš”ì²­:**
```json
{
  "word": "hÃ¤ngt",
  "sentence": "Diese groÃŸe Spanne hÃ¤ngt von mehreren Faktoren ab.",
  "language": "German"
}
```

**ì‘ë‹µ:**
```json
{
  "lemma": "abhÃ¤ngen",
  "definition": "ì˜ì¡´í•˜ë‹¤, ~ì— ë‹¬ë ¤ìˆë‹¤",
  "related_words": ["hÃ¤ngt", "ab"],
  "pos": "verb",
  "gender": null,
  "conjugations": {
    "present": "hÃ¤ngt ab",
    "past": "hing ab",
    "perfect": "hat abgehangen"
  },
  "level": "B1"
}
```

**íŠ¹ì§•:**
- **ë¶„ë¦¬ë™ì‚¬ ì²˜ë¦¬**: ë…ì¼ì–´ ë“±ì—ì„œ ë™ì‚¬ê°€ ë¶„ë¦¬ëœ ê²½ìš° ì „ì²´ lemma ë°˜í™˜ (ì˜ˆ: `hÃ¤ngt ... ab` â†’ `abhÃ¤ngen`)
- **ë³µí•©ì–´ ì²˜ë¦¬**: ë‹¨ì–´ê°€ ë³µí•©ì–´ì˜ ì¼ë¶€ì¸ ê²½ìš° ì „ì²´ í˜•íƒœ ë°˜í™˜
- **related_words**: ë¬¸ì¥ì—ì„œ ê°™ì€ lemmaì— ì†í•˜ëŠ” ëª¨ë“  ë‹¨ì–´ë“¤ì„ ë°°ì—´ë¡œ ë°˜í™˜ (ì˜ˆ: ë¶„ë¦¬ ë™ì‚¬ì˜ ê²½ìš° ëª¨ë“  ë¶€ë¶„ í¬í•¨)
- **ë¬¸ë²•ì  ë©”íƒ€ë°ì´í„°**: í’ˆì‚¬(pos), ì„±(gender), ë™ì‚¬ í™œìš©í˜•(conjugations), CEFR ë ˆë²¨(level) ìë™ ì¶”ì¶œ
- **ê³µí†µ ìœ í‹¸ ì‚¬ìš©**: `utils/llm.py`ì˜ `call_openai_chat()` í•¨ìˆ˜ í™œìš©
- **í”„ë¡¬í”„íŠ¸ ë¶„ë¦¬**: `utils/prompts.py`ì˜ `build_word_definition_prompt()` ì‚¬ìš©
- **ë³´ì•ˆ**: Regex injection ë°©ì§€ë¥¼ ìœ„í•œ `re.escape()` ì ìš©

**íë¦„:**

```mermaid
sequenceDiagram
    participant Frontend as Frontend<br/>(MarkdownViewer)
    participant NextAPI as Next.js API<br/>(/api/dictionary/search)
    participant FastAPI as FastAPI<br/>(/dictionary/search)
    participant Utils as Utils<br/>(prompts.py + llm.py)
    participant OpenAI as OpenAI API

    Frontend->>NextAPI: POST /api/dictionary/search<br/>{word, sentence, language}
    NextAPI->>FastAPI: POST /dictionary/search<br/>{word, sentence, language}

    FastAPI->>Utils: build_word_definition_prompt()
    Utils-->>FastAPI: prompt string

    FastAPI->>Utils: call_openai_chat(prompt)
    Utils->>OpenAI: POST /v1/chat/completions
    OpenAI-->>Utils: {lemma, definition, related_words, pos, gender, conjugations, level}
    Utils->>Utils: parse_json_from_content()
    Utils-->>FastAPI: {lemma, definition, related_words, pos, gender, conjugations, level}

    FastAPI-->>NextAPI: SearchResponse<br/>{lemma, definition, related_words, pos, gender, conjugations, level}
    NextAPI-->>Frontend: {lemma, definition, related_words, pos, gender, conjugations, level}
```

---

## ğŸ¨ Frontend Architecture

### Code Organization

The frontend follows a modular architecture with clear separation of concerns:

```
src/web/
â”œâ”€â”€ app/              # Next.js App Router (pages)
â”œâ”€â”€ components/       # Reusable React components
â”œâ”€â”€ hooks/            # Custom React hooks
â”œâ”€â”€ lib/              # Utility functions
â””â”€â”€ types/            # TypeScript type definitions
```

### Utility Modules

#### API Client (`lib/api.ts`)
Centralized API client utilities for consistent request handling:
- `fetchWithAuth()`: Automatic JWT token injection
- `parseErrorResponse()`: Consistent error message extraction

**Benefits**:
- DRY principle: Authentication logic in one place
- Consistent error handling across all API calls
- Easy to add global request interceptors

#### Date Formatters (`lib/formatters.ts`)
Reusable date formatting functions using Intl.DateTimeFormat:
- `formatDate()`: Customizable date formatting
- `formatDateShort()`: Short date format
- `formatDateTime()`: Date with time

**Benefits**:
- Consistent date display across UI
- Locale-aware formatting
- Single source of truth for date formats

#### Style Helpers (`lib/styleHelpers.ts`)
CEFR level badge styling utilities:
- `getLevelColor()`: Tailwind classes for level badges
- `getLevelLabel()`: Human-readable level labels

**Benefits**:
- Consistent color scheme across UI
- Dynamic class generation for Tailwind
- Easy to update color scheme globally

**Important**: CEFR level colors are safelisted in `tailwind.config.ts` to prevent Tailwind's tree-shaking from removing dynamically-generated classes.

### Custom Hooks

#### useAsyncFetch
Generic hook for async data fetching with automatic state management:
- Loading state
- Error handling
- Automatic 401 redirect
- Type-safe data state

**Use Cases**:
- Fetching article lists
- Loading article details
- Any API data fetching

#### usePagination
Pagination calculations and state management:
- Current page calculation
- Total pages calculation
- Next/previous page navigation
- Skip value computation

**Use Cases**:
- Article list pagination
- Vocabulary list pagination

#### useStatusPolling
Job status polling with automatic interval management:
- Configurable polling interval
- Automatic cleanup on completion/error
- Progress state management
- Callbacks for status changes

**Use Cases**:
- Article generation progress tracking
- Any long-running job monitoring

#### useVocabularyDelete
Vocabulary deletion with error handling:
- DELETE request to API
- Detailed error messages
- Throws errors for caller to handle

**Use Cases**:
- Deleting vocabulary entries from vocabulary list

### Reusable Components

#### ErrorAlert (`src/web/components/ErrorAlert.tsx`)
Consistent error message display:
- Red background with border (`bg-red-50 border-red-200`)
- Optional retry button with hover effect
- Automatic hiding when error is null
- Accessible error messaging

**Props**:
- `error` (string | null): Error message to display
- `onRetry` (optional): Callback function for retry button
- `className` (optional): Additional CSS classes

#### EmptyState (`src/web/components/EmptyState.tsx`)
Consistent empty state display:
- Centered layout with white card background
- Optional icon (emoji or Unicode character)
- Optional action button with blue styling
- Title and description text with gray tones

**Props**:
- `title` (string): Main heading text
- `description` (string): Descriptive subtitle
- `icon` (optional): Emoji or icon character
- `action` (optional): Object with `label` and `onClick` for action button
- `className` (optional): Additional CSS classes

**Benefits**:
- Consistent UX across all pages
- Reduces code duplication
- Easy to update design globally
- Improves maintainability with single source of truth

### Refactoring Impact

**Before Refactoring**:
- Duplicate fetch logic in every page
- Inconsistent error handling
- Duplicate date formatting code
- Duplicate pagination calculations
- Duplicate empty state styling

**After Refactoring**:
- Single source of truth for common operations
- Consistent error handling with `useAsyncFetch`
- Reusable date formatters
- Reusable pagination hook
- Reusable UI components (`ErrorAlert`, `EmptyState`)

**Code Reduction**:
- Article detail page: 166 lines reduced
- Articles list page: 27 lines reduced
- Vocabulary page: 43 lines reduced
- Total: 236 lines of code removed through refactoring

### Security Improvements

#### XSS Prevention in MarkdownViewer (`src/web/components/MarkdownViewer.tsx`)

**Issue**: Previous implementation used `innerHTML` to inject vocabulary buttons, creating XSS vulnerability.

**Security Measures Implemented**:

1. **HTML Escaping** (lines 92-96):
   - `escapeHtml()` utility converts text to DOM text node then reads innerHTML
   - Prevents script injection in user-provided content (word, lemma, definition, sentence)
   - Applied to all vocabulary data before rendering

2. **DOM API Methods** (lines 663-713):
   - Replaced `innerHTML` with DOM manipulation (`createElement`, `textContent`)
   - Creates definition spans using `document.createElement()` instead of string templates
   - Uses `textContent` for user data instead of `innerHTML`
   - Parses button HTML in temporary container, then extracts element reference

3. **Event Delegation** (lines 514-534):
   - Single event listener on container instead of per-word listeners
   - Prevents stale closure issues with dynamic content
   - Ref-based callback storage (`handleWordClickRef`) avoids outdated state

4. **Data Attribute Escaping** (lines 112-131):
   - All data attributes escaped before setting: `data-word="${wordEscaped}"`
   - JSON strings escaped with `.replace(/"/g, '&quot;')` for attribute safety
   - Prevents attribute injection attacks

**Before (Vulnerable)**:
```typescript
// Direct innerHTML injection - XSS risk
defSpan.innerHTML = `<strong>${lemma}</strong>: ${meaning} <button>...</button>`
```

**After (Secure)**:
```typescript
// DOM API - XSS safe
const strong = document.createElement('strong')
strong.textContent = displayLemma
defSpan.appendChild(strong)
defSpan.appendChild(document.createTextNode(': ' + meaning))
```

**Impact**: Prevents malicious script execution from vocabulary data, protects against DOM-based XSS attacks.

#### React Component Remounting Pattern

**Purpose**: Prevent React hydration mismatches when article content changes.

**Implementation** (`src/web/app/articles/[id]/page.tsx:266`):
```typescript
<MarkdownViewer
  key={`${articleId}-${content.length}`}
  content={content}
  language={article?.language}
  articleId={articleId}
  vocabularies={vocabularies}
  onAddVocabulary={handleAddVocabulary}
/>
```

**Key Prop Strategy**:
- Pattern: `${articleId}-${content.length}`
- Forces complete component remount when content changes
- Triggers reset of `data-processed` attribute (line 456)
- Clears all previous DOM state and event listeners

**Processing State Check** (`src/web/components/MarkdownViewer.tsx:456-458`):
```typescript
// Skip if already processed (component remounts on content change via key prop)
if (containerRef.current.getAttribute('data-processed') === 'true') {
  return
}
```

**Why This Pattern**:
- Without key: React reuses DOM nodes, causing hydration mismatches
- Manual cleanup: Error-prone and complex to maintain
- useEffect on content: Risk of double-processing
- Remounting: Clean state guaranteed, simple lifecycle

**Benefits**:
- Eliminates React DOM mismatch errors
- Prevents stale event listeners
- Simplifies component update logic
- Ensures consistent behavior across content changes

### Bug Fixes

#### 1. Conjugations Type Conversion
**Issue**: Frontend expected conjugations as object, but backend returned null for non-verbs, causing type mismatches.

**Fix**: Ensure conjugations field is properly typed and handled as nullable in TypeScript types.

#### 2. Tailwind Safelist for Dynamic Classes
**Issue**: CEFR level color classes (generated dynamically by `getLevelColor()`) were being purged by Tailwind's tree-shaking.

**Fix**: Added safelist to `tailwind.config.ts` to preserve dynamic color classes:
```typescript
safelist: [
  'bg-gray-100', 'text-gray-600',   // Unknown level
  'bg-green-100', 'text-green-700', // A1-A2
  'bg-yellow-100', 'text-yellow-700', // B1-B2
  'bg-red-100', 'text-red-700',     // C1-C2
]
```

**Impact**: CEFR level badges now display correctly with proper colors

### Vocabulary Management Endpoints

**Endpoints:**
- `POST /dictionary/vocabularies` - Add vocabulary
- `GET /dictionary/vocabularies` - Get vocabulary list (optionally filtered by article_id)
- `DELETE /dictionary/vocabularies/{id}` - Delete vocabulary
- `GET /dictionary/stats` - Get vocabulary statistics (word counts by language)

**Vocabulary ì €ì¥:**
- MongoDB `vocabularies` ì»¬ë ‰ì…˜ì— ì €ì¥
- `related_words` ë°°ì—´ í¬í•¨ (ë¶„ë¦¬ ë™ì‚¬ ë“± ë³µì¡í•œ ì–¸ì–´ êµ¬ì¡° ì§€ì›)
- Articleë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ê´€ë¦¬

**Vocabulary í‘œì‹œ:**
- ì €ì¥ëœ ë‹¨ì–´ëŠ” ì´ˆë¡ìƒ‰ìœ¼ë¡œ í•˜ì´ë¼ì´íŠ¸
- `related_words`ì— í¬í•¨ëœ ë‹¨ì–´ë“¤ë„ í•¨ê»˜ ì´ˆë¡ìƒ‰ í‘œì‹œ
- ì˜ˆ: "hÃ¤ngt" ì €ì¥ ì‹œ "ab"ë„ ìë™ìœ¼ë¡œ ì´ˆë¡ìƒ‰ í‘œì‹œ

---

## ğŸ§ª Testing Infrastructure

### Web Testing (Vitest)

**Configuration**: `src/web/vitest.config.ts`

**Test Environment**:
- **Framework**: Vitest 4.0.18 with jsdom for DOM simulation
- **UI**: @vitest/ui for interactive test running
- **Testing Library**: @testing-library/react for component testing
- **Test Matchers**: @testing-library/jest-dom for DOM assertions

**Coverage Settings**:
- Provider: v8 (Node.js native coverage)
- Reporters: text, json, html
- Thresholds: 80% for lines, functions, branches, statements
- Excludes: node_modules, test files, test directories

**Test Location**:
- Pattern: `**/__tests__/**/*.test.ts` and `**/__tests__/**/*.test.tsx`
- Current test files:
  - `hooks/__tests__/usePagination.test.ts`
  - `hooks/__tests__/useStatusPolling.test.ts`
  - `lib/__tests__/api.test.ts`
  - `lib/__tests__/formatters.test.ts`
  - `lib/__tests__/styleHelpers.test.ts`

**Run Commands** (`src/web/package.json`):
```bash
npm test         # Run all tests once
npm run test:watch   # Watch mode for development
npm run test:ui      # Interactive UI for test exploration
```

**Alias Resolution**:
- `@` alias resolves to `src/web/` directory
- Matches Next.js path configuration for consistency

**Benefits**:
- Fast test execution with Vitest (ESM-native)
- Interactive UI for debugging
- Coverage reporting for quality assurance
- Type-safe testing with TypeScript
